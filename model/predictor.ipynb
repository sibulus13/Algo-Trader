{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = r'D:\\repo\\stonks\\data\\dataset'\n",
    "\n",
    "def file_path(sym, type, file_type = 'csv', dir = DATASET_DIR):\n",
    "    return os.path.join(dir, f'{sym}_{type}.{file_type}')\n",
    "\n",
    "sym = 'AAPL'\n",
    "input_df = pd.read_csv(file_path(sym, 'inputs'))\n",
    "output_df = pd.read_csv(file_path(sym, 'outputs'))\n",
    "# input_df.columns, output_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1277361, 94)\n",
      "(1277361, 75)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import maxabs_scale\n",
    "import numpy as np\n",
    "print(input_df.shape)\n",
    "input_df.dropna(inplace=True, axis=1)\n",
    "print(input_df.shape)\n",
    "input = input_df.set_index('open').drop(columns=['Unnamed: 0']).values\n",
    "normalized_input = maxabs_scale(input, axis=0)\n",
    "# normalized_input = input / input.max(axis=0)\n",
    "output_h = output_df['highest_in_5_days'].values\n",
    "output_l = output_df['lowest_in_5_days'].values\n",
    "def lenient_accuracy(y_true, y_pred, threshold=0.02):\n",
    "    '''\n",
    "    y_true: true values\n",
    "    y_pred: predicted values\n",
    "    threshold: threshold for leniency\n",
    "    \n",
    "    returns the percentage of predictions that are within the threshold \n",
    "    '''\n",
    "    return np.mean((y_true - y_pred) <= threshold)\n",
    "\n",
    "def lenient_scorer(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return lenient_accuracy(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1021888, 73) (255473, 73) (1021888,) (255473,)\n",
      "saved LinearRegression predictor_info.joblib\n",
      "{'model_name': 'LinearRegression', 'duration': 16.5, 'k_fold_lenient': 0.6838, 'lenient_score': 0.6819, 'raw_score': 0.9088, 'comment': '', 'model': LinearRegression()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.8239e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.77258e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.78116e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.71965e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.75912e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.79062e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved Ridge predictor_info.joblib\n",
      "{'model_name': 'Ridge', 'duration': 3.12, 'k_fold_lenient': 0.6839, 'lenient_score': 0.6819, 'raw_score': 0.9088, 'comment': '', 'model': Ridge()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.293e+08, tolerance: 5.326e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.814e+08, tolerance: 4.246e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.848e+08, tolerance: 4.265e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.806e+08, tolerance: 4.266e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.865e+08, tolerance: 4.263e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.840e+08, tolerance: 4.263e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved Lasso predictor_info.joblib\n",
      "{'model_name': 'Lasso', 'duration': 393.62, 'k_fold_lenient': 0.6861, 'lenient_score': 0.6845, 'raw_score': 0.9091, 'comment': '', 'model': Lasso()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.291e+08, tolerance: 5.326e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.812e+08, tolerance: 4.246e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.846e+08, tolerance: 4.265e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.804e+08, tolerance: 4.266e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.863e+08, tolerance: 4.263e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.838e+08, tolerance: 4.263e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ElasticNet predictor_info.joblib\n",
      "{'model_name': 'ElasticNet', 'duration': 188.35, 'k_fold_lenient': 0.6861, 'lenient_score': 0.6847, 'raw_score': 0.9091, 'comment': '', 'model': ElasticNet()}\n",
      "saved DecisionTreeRegressor predictor_info.joblib\n",
      "{'model_name': 'DecisionTreeRegressor', 'duration': 498.88, 'k_fold_lenient': 0.9846, 'lenient_score': 0.9866, 'raw_score': 0.9996, 'comment': '', 'model': DecisionTreeRegressor()}\n",
      "saved ExtraTreeRegressor predictor_info.joblib\n",
      "{'model_name': 'ExtraTreeRegressor', 'duration': 55.9, 'k_fold_lenient': 0.9801, 'lenient_score': 0.9839, 'raw_score': 0.9996, 'comment': '', 'model': ExtraTreeRegressor()}\n",
      "saved HistGradientBoostingRegressor predictor_info.joblib\n",
      "{'model_name': 'HistGradientBoostingRegressor', 'duration': 41.91, 'k_fold_lenient': 0.5543, 'lenient_score': 0.5577, 'raw_score': 0.9982, 'comment': '', 'model': HistGradientBoostingRegressor()}\n",
      "(1021888, 73) (255473, 73) (1021888,) (255473,)\n",
      "saved LinearRegression predictor_info.joblib\n",
      "{'model_name': 'LinearRegression', 'duration': 18.24, 'k_fold_lenient': 0.4674, 'lenient_score': 0.4657, 'raw_score': 0.9444, 'comment': '', 'model': LinearRegression()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.8239e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.77258e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.78116e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.71965e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.75912e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.79062e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved Ridge predictor_info.joblib\n",
      "{'model_name': 'Ridge', 'duration': 3.34, 'k_fold_lenient': 0.4674, 'lenient_score': 0.4657, 'raw_score': 0.9444, 'comment': '', 'model': Ridge()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e+08, tolerance: 4.185e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.861e+07, tolerance: 3.342e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e+08, tolerance: 3.350e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+08, tolerance: 3.354e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e+08, tolerance: 3.345e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.008e+08, tolerance: 3.349e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved Lasso predictor_info.joblib\n",
      "{'model_name': 'Lasso', 'duration': 210.02, 'k_fold_lenient': 0.4662, 'lenient_score': 0.4641, 'raw_score': 0.9443, 'comment': '', 'model': Lasso()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+08, tolerance: 4.185e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.840e+07, tolerance: 3.342e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+08, tolerance: 3.350e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+08, tolerance: 3.354e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+08, tolerance: 3.345e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e+08, tolerance: 3.349e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ElasticNet predictor_info.joblib\n",
      "{'model_name': 'ElasticNet', 'duration': 140.94, 'k_fold_lenient': 0.4659, 'lenient_score': 0.4636, 'raw_score': 0.9443, 'comment': '', 'model': ElasticNet()}\n",
      "saved DecisionTreeRegressor predictor_info.joblib\n",
      "{'model_name': 'DecisionTreeRegressor', 'duration': 481.13, 'k_fold_lenient': 0.9849, 'lenient_score': 0.9871, 'raw_score': 1.0, 'comment': '', 'model': DecisionTreeRegressor()}\n",
      "saved ExtraTreeRegressor predictor_info.joblib\n",
      "{'model_name': 'ExtraTreeRegressor', 'duration': 56.04, 'k_fold_lenient': 0.9789, 'lenient_score': 0.9819, 'raw_score': 0.9997, 'comment': '', 'model': ExtraTreeRegressor()}\n",
      "saved HistGradientBoostingRegressor predictor_info.joblib\n",
      "{'model_name': 'HistGradientBoostingRegressor', 'duration': 43.49, 'k_fold_lenient': 0.4557, 'lenient_score': 0.4526, 'raw_score': 0.9981, 'comment': '', 'model': HistGradientBoostingRegressor()}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(normalized_input, output_h, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# import all regression models for continuous output\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, BaggingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "# fitted_model = LinearRegression().fit(x_train, y_train)\n",
    "# fitted_model.score(x_test, y_test)\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    ElasticNet(),\n",
    "    DecisionTreeRegressor(),\n",
    "    ExtraTreeRegressor(),\n",
    "    HistGradientBoostingRegressor(),\n",
    "    # SVR(),\n",
    "    # AdaBoostRegressor(), # 11470.01s = 3.2 hours\n",
    "    # RandomForestRegressor(), # takes too long, 89285.37s = 24.8 hours = 1 day\n",
    "    # GradientBoostingRegressor(), # takes too long, 53585.16s = 14.8 hours = 1 day\n",
    "    # KNeighborsRegressor(), # takes too long,  5299/2s = 88.3 minutes = 1.5 hours\n",
    "    # MLPRegressor(), # takes too long,  26224/2s = 437 minutes = 7.3 hours\n",
    "    # BaggingRegressor(), # takes too long,  5684/2s = 94.7 minutes = 1.5 hours\n",
    "] \n",
    "import time\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "from pathlib import Path\n",
    "results = []\n",
    "# for model in models:\n",
    "k_fold = KFold(n_splits=5, shuffle=False)\n",
    "#     score_k = cross_val_score(LinearRegression(), x_train, y_train, cv=k_fold, n_jobs=1, scoring=lenient_scorer)\n",
    "save = True\n",
    "datasets = {'highs': output_h, 'lows': output_l}\n",
    "for prediction_type, output in datasets.items():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(input, output, test_size=0.2, random_state=42)\n",
    "    # y_train = y_train.reshape(-1, 1)\n",
    "    # y_test = y_test.reshape(-1, 1)\n",
    "    # x_train = x_train.astype(np.float16)\n",
    "    # x_test = x_test.astype(np.float16)\n",
    "    # y_train = y_train.astype(np.float16)\n",
    "    # y_test = y_test.astype(np.float16)\n",
    "    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "    for model in models:\n",
    "            # start timer\n",
    "            start = time.time()\n",
    "            model_name = model.__class__.__name__\n",
    "            try:\n",
    "                fitted_model = model.fit(x_train, y_train)\n",
    "                raw_score = fitted_model.score(x_test, y_test)\n",
    "                lenient_score = lenient_accuracy(y_test, fitted_model.predict(x_test))\n",
    "                score_k = cross_val_score(model,\n",
    "                                        x_train,\n",
    "                                        y_train,\n",
    "                                        cv=k_fold,scoring=lenient_scorer)\n",
    "            \n",
    "                # end timer\n",
    "                end = time.time()\n",
    "                result = {\n",
    "                    'model_name': model_name,\n",
    "                    'duration': round(end - start, 2),\n",
    "                    'k_fold_lenient': round(np.mean(score_k),4),\n",
    "                    'lenient_score': round(lenient_score, 4),\n",
    "                    'raw_score': round(raw_score, 4),\n",
    "                    'comment': '',\n",
    "                    'model': fitted_model\n",
    "                    }\n",
    "                s = pickle.dumps(fitted_model)\n",
    "                if save:\n",
    "                    Path(os.path.join(DATASET_DIR, f'{sym}')).mkdir(parents = True, exist_ok=True)\n",
    "                    dump(result, os.path.join(DATASET_DIR, f'{sym}', f'predictor_{prediction_type}_{model_name}.joblib'))\n",
    "                    print(f'saved {model_name} predictor_info.joblib')\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                # end timer\n",
    "                end = time.time()\n",
    "                result = {\n",
    "                    'model_name': f'{model_name}_{prediction_type}',\n",
    "                    'duration': round(end - start, 2),\n",
    "                    'k_fold_lenient': -1,\n",
    "                    'lenient_score': -1,\n",
    "                    'raw_score': -1,\n",
    "                    'comment': e,\n",
    "                }\n",
    "            finally:\n",
    "                results.append(result)\n",
    "                print(result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       model_name  duration  k_fold_lenient  lenient_score  \\\n",
      "11          DecisionTreeRegressor    481.13          0.9849         0.9871   \n",
      "4           DecisionTreeRegressor    498.88          0.9846         0.9866   \n",
      "5              ExtraTreeRegressor     55.90          0.9801         0.9839   \n",
      "12             ExtraTreeRegressor     56.04          0.9789         0.9819   \n",
      "2                           Lasso    393.62          0.6861         0.6845   \n",
      "3                      ElasticNet    188.35          0.6861         0.6847   \n",
      "1                           Ridge      3.12          0.6839         0.6819   \n",
      "0                LinearRegression     16.50          0.6838         0.6819   \n",
      "6   HistGradientBoostingRegressor     41.91          0.5543         0.5577   \n",
      "7                LinearRegression     18.24          0.4674         0.4657   \n",
      "8                           Ridge      3.34          0.4674         0.4657   \n",
      "9                           Lasso    210.02          0.4662         0.4641   \n",
      "10                     ElasticNet    140.94          0.4659         0.4636   \n",
      "13  HistGradientBoostingRegressor     43.49          0.4557         0.4526   \n",
      "\n",
      "    raw_score comment                            model  \n",
      "11     1.0000                  DecisionTreeRegressor()  \n",
      "4      0.9996                  DecisionTreeRegressor()  \n",
      "5      0.9996                     ExtraTreeRegressor()  \n",
      "12     0.9997                     ExtraTreeRegressor()  \n",
      "2      0.9091                                  Lasso()  \n",
      "3      0.9091                             ElasticNet()  \n",
      "1      0.9088                                  Ridge()  \n",
      "0      0.9088                       LinearRegression()  \n",
      "6      0.9982          HistGradientBoostingRegressor()  \n",
      "7      0.9444                       LinearRegression()  \n",
      "8      0.9444                                  Ridge()  \n",
      "9      0.9443                                  Lasso()  \n",
      "10     0.9443                             ElasticNet()  \n",
      "13     0.9981          HistGradientBoostingRegressor()  \n"
     ]
    }
   ],
   "source": [
    "# sort results by k_fold_lenient and lenient_score\n",
    "result = pd.DataFrame(results)\n",
    "result = result.sort_values(by=['k_fold_lenient', 'duration', 'lenient_score'], ascending=False)\n",
    "# print(result)\n",
    "results_without_error = result[result['k_fold_lenient'] != -1]\n",
    "print(results_without_error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
